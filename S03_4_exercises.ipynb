{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Words, Tokens, and Regular Expressions\n",
    "## Exercises Notebook - Session 3\n",
    "\n",
    "This notebook contains exercises covering:\n",
    "- Tokenization concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Tokenization Concepts\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Types vs Instances\n",
    "\n",
    "The slides distinguish between types and instances.\n",
    "For the given text, calculate:\n",
    "1. Number of instances (total tokens)\n",
    "2. Number of types (vocabulary size |V|)\n",
    "3. Type-token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "text = \"the cat sat on the mat the cat was fat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Heaps' Law Demonstration\n",
    "\n",
    "The slides mention Heaps' Law: vocabulary size grows with âˆšN.\n",
    "\n",
    "Generate text of increasing length and observe vocabulary growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import random\n",
    "\n",
    "# Use a simple word list to simulate text\n",
    "word_list = ['the', 'a', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "             'cat', 'dog', 'bird', 'fish', 'tree', 'house', 'car',\n",
    "             'run', 'walk', 'jump', 'eat', 'sleep', 'read', 'write',\n",
    "             'big', 'small', 'fast', 'slow', 'red', 'blue', 'green']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: BPE Simulation\n",
    "\n",
    "The slides explain Byte Pair Encoding (BPE).\n",
    "Implement a simple BPE token learner that:\n",
    "1. Starts with character vocabulary\n",
    "2. Finds most frequent adjacent pair\n",
    "3. Merges them into a new token\n",
    "4. Repeats k times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "corpus = \"low lower newest widest\"\n",
    "\n",
    "def simple_bpe(corpus, num_merges):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Advanced Regex\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Lookahead Assertions\n",
    "\n",
    "The slides introduce lookahead: (?=pattern) and (?!pattern)\n",
    "\n",
    "Write patterns to:\n",
    "1. Find words followed by a comma (without capturing comma)\n",
    "2. Find first word of line only if it doesn't start with 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "text = \"The quick, brown fox jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Non-capturing Groups\n",
    "\n",
    "The slides explain (?:...) for grouping without capturing.\n",
    "\n",
    "Write a pattern that matches \"some cats\" or \"a few cats\" \n",
    "but only captures \"cats\" (not \"some\" or \"a few\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "texts = [\n",
    "    \"some cats like fish\",\n",
    "    \"a few cats play outside\", \n",
    "    \"some dogs bark\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: GPT-2 Pre-tokenization\n",
    "\n",
    "The slides show the GPT-2 pre-tokenization regex.\n",
    "Test the pattern and understand what each part does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "gpt2_pattern = r\"'s|'t|'re|'ve|'m|'ll|'d|\\w+|\\d+|[^\\s\\w]+\"\n",
    "test = \"I'm learning NLP! It's fascinating. I've got 100 examples.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Morphology\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Identifying Morphemes\n",
    "\n",
    "The slides define morphemes as minimal meaning-bearing units.\n",
    "\n",
    "Write code to identify potential morphemes by finding:\n",
    "1. Common suffixes (-ed, -ing, -s, -ly, -ful)\n",
    "2. Common prefixes (un-, re-, pre-, dis-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "words = [\"working\", \"unhappy\", \"carefully\", \"reworked\", \"glasses\", \"preprocessing\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
