{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# S07 - Word Embeddings & Neural Networks\n", "## Exercises"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 (Easy)\n", "Load pre-trained Word2Vec embeddings and find similar words."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import gensim.downloader as api\n", "\n", "# Load pre-trained word2vec (google-news-300 or glove-wiki-gigaword-100)\n", "# Find top 5 most similar words to 'king'\n"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 (Easy)\n", "Perform word analogy: king - man + woman = ?"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use the model to solve: king - man + woman = ?\n", "# Also try: paris - france + spain = ?\n"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3 (Medium)\n", "Train your own Word2Vec model on a custom corpus."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from gensim.models import Word2Vec\n", "\n", "corpus = [\n", "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n", "    [\"the\", \"dog\", \"ran\", \"in\", \"the\", \"park\"],\n", "    [\"cats\", \"and\", \"dogs\", \"are\", \"pets\"],\n", "    [\"the\", \"cat\", \"chased\", \"the\", \"dog\"],\n", "    [\"pets\", \"need\", \"food\", \"and\", \"water\"]\n", "]\n", "\n", "# Train Word2Vec model (vector_size=50, window=3, min_count=1)\n"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 4 (Medium)\n", "Build a simple neural network for text classification using embeddings."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "\n", "class TextClassifier(nn.Module):\n", "    def __init__(self, vocab_size, embed_dim, num_classes):\n", "        super().__init__()\n", "        # Define: embedding layer, linear layer\n", "        pass\n", "    \n", "    def forward(self, x):\n", "        # Embed -> mean pooling -> classify\n", "        pass\n", "\n", "# Test with dummy data\n"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 5 (Hard)\n", "Implement the Skip-gram model from scratch (forward pass only).\n", "\n", "*Research: Skip-gram predicts context words given center word.*"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "\n", "class SkipGram(nn.Module):\n", "    def __init__(self, vocab_size, embed_dim):\n", "        super().__init__()\n", "        # Two embedding matrices: center and context\n", "        pass\n", "    \n", "    def forward(self, center, context):\n", "        # Return dot product scores\n", "        pass\n"]}
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.9.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}